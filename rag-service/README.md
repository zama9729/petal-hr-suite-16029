# HR RAG Service

Production-ready, multi-tenant RAG (Retrieval-Augmented Generation) service for HR/Employee Management systems.

## Features

- **Multi-tenant isolation**: Vector namespaces per tenant, enforced at every layer
- **RBAC**: Role-based access control (Employee, Manager, HR, CEO)
- **JWT Authentication**: Secure token-based auth with tenant validation
- **Document Ingestion**: PDF, DOCX, TXT support with PII detection & redaction
- **LLM Integration**: OpenAI-compatible with function calling
- **Async Processing**: Celery workers for embedding generation
- **Vector Store**: Chroma (with FAISS fallback)
- **Audit Logging**: Immutable audit trail with PII masking
- **Caching**: Redis caching for queries and embeddings

## Architecture

```
┌─────────────┐
│  FastAPI    │
│   (API)     │
└──────┬──────┘
       │
   ┌───┴───┐
   │       │
┌──▼──┐ ┌──▼────┐
│Postgres│ │ Redis │
└───┬──┘ └───┬───┘
    │        │
    │    ┌───▼────┐
    │    │ Celery │
    │    │ Workers│
    │    └───┬────┘
    │        │
    └───┬────┴──┐
        │       │
    ┌───▼───┐ ┌─▼────┐
    │Chroma │ │ LLM  │
    │Vector │ │ API  │
    │ Store │ │      │
    └───────┘ └──────┘
```

## Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local development)
- OpenAI API key (or compatible service)

### 1. Clone and Setup

```bash
cd rag-service
cp .env.example .env
# Edit .env with your OpenAI API key
```

### 2. Start Services

```bash
docker-compose up -d
```

This starts:
- Postgres (port 5433)
- Redis (port 6381)
- Chroma (port 8000)
- RAG API (port 8001)
- Celery Worker

### 3. Run Migrations

```bash
docker-compose exec rag-api alembic upgrade head
```

### 4. Seed Sample Data

```bash
docker-compose exec rag-api python scripts/seed_data.py
```

This creates:
- Sample tenant (Acme Corporation)
- Sample employees (Employee, Manager, HR, CEO)
- Sample paystubs and leave requests
- Sample JWT tokens for testing

### 5. Test API

```bash
# Health check
curl http://localhost:8001/health

# Query (use JWT from seed script)
curl -X POST http://localhost:8001/api/v1/query \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"query": "What is my leave balance?"}'
```

## API Endpoints

### `POST /api/v1/query`

Natural language query with RAG retrieval.

**Request:**
```json
{
  "query": "What is my leave balance?",
  "top_k": 5,
  "use_tools": true
}
```

**Response:**
```json
{
  "answer": "Your leave balance is 15 days remaining...",
  "provenance": {
    "top_doc_ids": ["doc-uuid-1", "doc-uuid-2"],
    "chunk_ids": ["chunk-uuid-1"],
    "snippets": ["According to Document 1..."],
    "confidence": 0.85
  },
  "tool_calls": [
    {
      "name": "get_leave_balance",
      "result": {"remaining_days": 15}
    }
  ],
  "latency_ms": 1234,
  "request_id": "req-uuid"
}
```

### `POST /api/v1/ingest`

Upload document for ingestion.

**Request:**
```bash
curl -X POST http://localhost:8001/api/v1/ingest \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -F "file=@policy.pdf" \
  -F "is_confidential=false"
```

**Response:**
```json
{
  "job_id": "celery-job-uuid",
  "document_id": "doc-uuid",
  "status": "processing",
  "message": "Document ingestion started"
}
```

### `POST /api/v1/tool_call`

Direct tool call (internal use).

**Request:**
```json
{
  "tool_name": "get_leave_balance",
  "arguments": {
    "employee_id": "emp-uuid"
  }
}
```

### `GET /api/v1/audit`

Get audit logs (admin-only).

**Query Parameters:**
- `limit`: Number of logs (default: 100)

## JWT Token Format

JWT tokens must include:

```json
{
  "sub": "user-uuid",
  "tenant_id": "tenant-uuid",
  "email": "user@example.com",
  "role": "employee|manager|hr|ceo",
  "exp": 1234567890
}
```

### Sample Tokens (from seed script)

**Employee:**
```bash
# Token for john.doe@acme.com (employee role)
# Generated by seed script
```

**Manager:**
```bash
# Token for jane.smith@acme.com (manager role)
# Generated by seed script
```

## Tool Functions

The LLM can call these tools via function calling:

1. **`get_leave_balance(tenant_id, employee_id)`**
   - Returns annual entitlement, used days, remaining days

2. **`list_recent_paystubs(tenant_id, employee_id, n=3)`**
   - Returns recent paystubs for employee

3. **`create_leave_request(tenant_id, employee_id, from_date, to_date, reason)`**
   - Creates a new leave request

4. **`approve_leave(tenant_id, approver_id, leave_id)`**
   - Approves leave request (requires manager/HR/CEO role)

5. **`summarize_policy(tenant_id, doc_id)`**
   - Summarizes a policy document

## Environment Variables

See `.env.example` for full list. Key variables:

- `DATABASE_URL`: Postgres connection string
- `REDIS_URL`: Redis connection string
- `CHROMA_URL`: Chroma vector store URL
- `OPENAI_API_KEY`: OpenAI API key
- `JWT_SECRET`: Secret for JWT signing
- `CHUNK_SIZE`: Text chunk size (default: 800)
- `CHUNK_OVERLAP`: Chunk overlap (default: 200)
- `PII_REDACTION_ENABLED`: Enable PII redaction (default: true)

## Development

### Local Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run migrations
alembic upgrade head

# Seed data
python scripts/seed_data.py

# Run API
uvicorn app.main:app --reload

# Run Celery worker (separate terminal)
celery -A app.celery_app worker --loglevel=info
```

### Running Tests

```bash
# Unit tests
pytest tests/test_auth.py -v
pytest tests/test_tools.py -v

# Integration tests
pytest tests/test_integration.py -v

# With coverage
pytest --cov=app --cov-report=html
```

### Adding New Tools

1. Add tool function to `app/tools.py`:

```python
def my_new_tool(self, tenant_id: str, arg1: str) -> Dict:
    """Tool description."""
    # Implementation
    return {"result": "..."}
```

2. Register in `register_tools()`:

```python
llm_service.register_tool(
    "my_new_tool",
    registry.my_new_tool,
    "Tool description",
    {
        "type": "object",
        "properties": {
            "tenant_id": {"type": "string"},
            "arg1": {"type": "string"}
        },
        "required": ["tenant_id", "arg1"]
    }
)
```

3. Update RBAC permissions in `app/auth.py` if needed.

## Production Deployment

### Security Checklist

- [ ] Change `JWT_SECRET` to strong random value
- [ ] Set `TLS_ENABLED=true` and configure certificates
- [ ] Set `ENCRYPTION_KEY_PLACEHOLDER` to actual encryption key
- [ ] Configure CORS appropriately
- [ ] Set up proper database backups
- [ ] Enable Prometheus metrics collection
- [ ] Configure log aggregation
- [ ] Set up monitoring alerts

### Scaling

- **API**: Scale FastAPI instances behind load balancer
- **Celery**: Scale workers based on ingestion load
- **Vector Store**: Chroma supports clustering; FAISS can be sharded
- **Database**: Use read replicas for queries
- **Redis**: Use Redis Cluster for high availability

## Troubleshooting

### Chroma Connection Failed

```bash
# Check Chroma is running
curl http://localhost:8000/api/v1/heartbeat

# If using FAISS fallback, set in .env:
USE_FAISS=true
FAISS_PATH=/app/faiss_index
```

### Embedding Generation Fails

- Check OpenAI API key is set correctly
- Verify API quota/rate limits
- Check network connectivity to OpenAI

### PII Detection Not Working

- Ensure `presidio-analyzer` and `presidio-anonymizer` are installed
- Check `PII_REDACTION_ENABLED=true` in .env

## License

MIT

